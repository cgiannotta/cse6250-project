{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqF7Y7mo087+4Ql+y+8YYi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["### TODO - CNN portion of project"],"metadata":{"id":"zAxncPYeRDsd"}},{"cell_type":"markdown","source":["1. Update metric to match those in paper (F1 score, precision, recall, AUC\n","2. Integrate phenotype dictionary to make selecting phenotype for Y-value in experiment easier (ie. not using a hard-coded integer)\n","3. Run experiments across all 10 phenotypes used in paper with default parameters\n","4. Repose this code\n","5. Add readMe\n","6. Create figure to compare F1 scores across phenotypes for the CNN"],"metadata":{"id":"qjXDbgx4RG7r"}},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"ZbbuUWh_PUfA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpJe_CXyKjrT"},"outputs":[],"source":["# Mount into drive\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Project/src')"],"metadata":{"id":"uOylTuH2wX-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root = '/content/drive/MyDrive/Project'"],"metadata":{"id":"L6iOsTELN-tE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir(root)\n","%pwd"],"metadata":{"id":"e414a1BxN8mO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect PY file updates and reload\n","%load_ext autoreload\n","%autoreload 0.5"],"metadata":{"id":"RcHPS7KrOoxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%ls"],"metadata":{"id":"vaB0DK6GOpdC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pwd"],"metadata":{"id":"A7hH9Wzjv6Kr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Installations"],"metadata":{"id":"6ct9MKHwPQTQ"}},{"cell_type":"code","source":["!pip install wandb -qqq"],"metadata":{"id":"jZtP5WBnAFXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","wandb.login()"],"metadata":{"id":"s-RLChRkCAyc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import logging\n","import time\n","import h5py\n","from platform import python_version\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.optim import Adam, Adadelta\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from platform import python_version\n","from torch.utils import data\n","\n","# Local imports\n","import src.CNN.CNN_NLP as cnn_model\n","from src.CNN.data_load import get_data\n","from src.CNN.run_model import run_model"],"metadata":{"id":"y2pqM-z5PYk_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"tnsl17dvu5pP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment"],"metadata":{"id":"EAh4HaJJR6_8"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","sweep_config = {\n","    'method': 'random', #grid, random\n","    'metric': {\n","      'name': 'val_accuracy',\n","      'goal': 'maximize'   \n","    },\n","    'parameters': {\n","        'h5py_file': {\n","            'value':'src/phenotyping/their-embeddings/data-nobatch.h5'\n","        },\n","        'batch_size': {\n","            'values':[32, 64, 128]\n","        },\n","        'filter_sizes': {\n","            'value':[2, 3, 4, 5]\n","        },\n","        'num_filters': {\n","            'value':[100, 100,100,100]\n","        },\n","        'num_classes': {\n","            'value':2\n","        },\n","        'dropout': {\n","            'values': [0.3, 0.5]\n","        },\n","        'learning_rate': {\n","            'values': [1e-1, 1e-2, 1e-3]\n","        },\n","        'phenotype': {\n","            'value': 0\n","        },\n","        'epochs': {\n","            'values':[1]\n","        },\n","        'opt': {\n","            'values':['ada']\n","        },\n","        'rho':{\n","            'values':[0.9, 0.95]\n","        },\n","        'freeze_embeddings':{\n","            'values':[True]\n","        }\n","    }\n","}\n","\n","def run():\n","  with wandb.init(project=\"cs6250-project\", entity=\"cs7643-teamscam\") as run:\n","    config = wandb.config\n","    \n","    # Parameters\n","    H5PY_FILE = config[\"h5py_file\"]\n","    BATCH_SIZE = config[\"batch_size\"]\n","    FILTER_SIZES = config[\"filter_sizes\"]\n","    NUM_FILTERS = config[\"num_filters\"]\n","    NUM_CLASSES = config[\"num_classes\"]\n","    DROPOUT = config[\"dropout\"]\n","    LEARNING_RATE = config[\"learning_rate\"]\n","    RHO = config[\"rho\"]\n","    PHENOTYPE = config[\"phenotype\"]\n","    EPOCHS = config[\"epochs\"]\n","    FREEZE_EMBEDDINGS = config[\"freeze_embeddings\"]\n","\n","    # Get Train and Validation DataLoader\n","    train_dataloader, val_dataloader, embeddings_tensor = get_data(H5PY_FILE, device, BATCH_SIZE, PHENOTYPE)\n","\n","    # Instantiate CNN model\n","    model = cnn_model.CNN_NLP(pretrained_embedding=embeddings_tensor,\n","                        freeze_embedding=FREEZE_EMBEDDINGS,\n","                        vocab_size=None,\n","                        embed_dim=300,\n","                        filter_sizes=FILTER_SIZES,\n","                        num_filters=NUM_FILTERS,\n","                        num_classes=NUM_CLASSES,\n","                        dropout=0.5)\n","    \n","    # Send model to `device` (GPU/CPU)\n","    model.to(device)\n","    \n","    # Instantiate Optimizer\n","    if (config['opt'] == 'adam'): \n","      optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    else:\n","      optimizer = optim.Adadelta(model.parameters(), lr=LEARNING_RATE, rho=RHO)\n","\n","    # Specify loss function\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    # Instantiate the model run\n","    run = run_model(model, optimizer, loss_fn, device)\n","\n","    # Run the train/validation\n","    results = run.train(train_dataloader, val_dataloader, EPOCHS)\n","\n","count = 1  # number of runs to execute\n","sweep_id = wandb.sweep(sweep_config, project=\"cs6250-project\", entity=\"cs7643-teamscam\")\n","wandb.agent(sweep_id, function=run, count=count)\n","\n","\n"],"metadata":{"id":"IqpjD9YMDpg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get Train and Validation DataLoader\n","train_dataloader, val_dataloader, embeddings_tensor = get_data(h5py_file, device, batch_size, phenotype)"],"metadata":{"id":"YiB-cxbTUKUz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# Instantiate CNN model\n","cnn_model = cnn_model.CNN_NLP(pretrained_embedding=embeddings_tensor,\n","                        freeze_embedding=freeze_embedding,\n","                        vocab_size=vocab_size,\n","                        embed_dim=300,\n","                        filter_sizes=filter_sizes,\n","                        num_filters=num_filters,\n","                        num_classes=2,\n","                        dropout=0.5)\n","    \n","# Send model to `device` (GPU/CPU)\n","cnn_model.to(device)\n","\n","# Instantiate Adadelta optimizer\n","optimizer = optim.Adadelta(cnn_model.parameters(),lr=learning_rate, rho=0.95)\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Instantiate the model run\n","run = run_model(cnn_model, optimizer, loss_fn, device)"],"metadata":{"id":"p6ZsqJkZwXcZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start the new run\n","run.train(train_dataloader, val_dataloader, epochs)"],"metadata":{"id":"JaL1CY00FNnW"},"execution_count":null,"outputs":[]}]}